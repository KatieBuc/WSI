{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46976620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.prepared import prep\n",
    "from shapely.geometry import Point\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from wsi.mapping.iso_name import ISO_NAME\n",
    "from wsi.mapping.iso_gw import ISO_GW\n",
    "from wsi.mapping.iso_iso2 import ISO_ISO2\n",
    "from wsi.utils import raw_data_path, processed_data_path\n",
    "\n",
    "# Constants\n",
    "EARTH_RADIUS_KM = 6371\n",
    "FILE_PATTERN = \"gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_30_sec_{tile}.asc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225e09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=processed_data_path(\"shocks\",\"proximity_conflict\", 'conflict_logs.log'),   # Output file path\n",
    "    filemode='a',                          # Append mode\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d018aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_population_count(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    with open(file_path, 'r') as f:\n",
    "        metadata = {}\n",
    "        for _ in range(6):\n",
    "            key, value = f.readline().strip().split()\n",
    "            metadata[key.lower()] = float(value)\n",
    "    data = np.loadtxt(file_path, skiprows=6)\n",
    "    gt = (\n",
    "        metadata['xllcorner'],\n",
    "        metadata['cellsize'],\n",
    "        0,\n",
    "        metadata['yllcorner'] + metadata['nrows'] * metadata['cellsize'],\n",
    "        0,\n",
    "        -metadata['cellsize']\n",
    "    )\n",
    "    return {\n",
    "        \"file\": file_path,\n",
    "        \"data\": data,\n",
    "        \"geotransform\": gt,\n",
    "        \"no_data_value\": metadata['nodata_value']\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_pixel_grid(geotransform, shape):\n",
    "    origin_x, pixel_w, _, origin_y, _, pixel_h = geotransform\n",
    "    rows, cols = shape\n",
    "    row_grid, col_grid = np.ogrid[0:rows, 0:cols]\n",
    "    lat_grid = origin_y + row_grid * pixel_h\n",
    "    lon_grid = origin_x + col_grid * pixel_w\n",
    "    lat_grid = np.broadcast_to(lat_grid, (rows, cols))\n",
    "    lon_grid = np.broadcast_to(lon_grid, (rows, cols))\n",
    "    return lat_grid, lon_grid\n",
    "\n",
    "def haversine_distance_vector(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1 = math.radians(lat1), math.radians(lon1)\n",
    "    lat2, lon2 = np.radians(lat2), np.radians(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    return EARTH_RADIUS_KM * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "def get_population_in_conflict_area(all_data, conflict_coords, radius_km=50):\n",
    "    total_population = 0\n",
    "    union_grid_points = []\n",
    "    radius_deg_lat = radius_km / 111.0\n",
    "\n",
    "    for dataset in all_data:\n",
    "        data = dataset[\"data\"]\n",
    "        gt = dataset[\"geotransform\"]\n",
    "        nodata = dataset[\"no_data_value\"]\n",
    "        lat_grid, lon_grid = prepare_pixel_grid(gt, data.shape)\n",
    "        mask = np.zeros(data.shape, dtype=bool)\n",
    "\n",
    "        for lat, lon in conflict_coords:\n",
    "            radius_deg_lon = radius_km / (111.0 * math.cos(math.radians(lat)))\n",
    "            lat_min, lat_max = lat - radius_deg_lat, lat + radius_deg_lat\n",
    "            lon_min, lon_max = lon - radius_deg_lon, lon + radius_deg_lon\n",
    "            conflict_mask = (\n",
    "                (lat_grid >= lat_min) & (lat_grid <= lat_max) &\n",
    "                (lon_grid >= lon_min) & (lon_grid <= lon_max)\n",
    "            )\n",
    "            dists = haversine_distance_vector(lat, lon, lat_grid[conflict_mask], lon_grid[conflict_mask])\n",
    "            tmp_mask = np.zeros_like(mask)\n",
    "            tmp_mask[conflict_mask] = dists <= radius_km\n",
    "            mask |= tmp_mask\n",
    "\n",
    "        valid_mask = mask & (data != nodata)\n",
    "        total_population += data[valid_mask].sum()\n",
    "        if np.any(valid_mask):\n",
    "            union_grid_points += np.column_stack((lat_grid[valid_mask], lon_grid[valid_mask], data[valid_mask])).tolist()\n",
    "\n",
    "    return total_population, union_grid_points\n",
    "\n",
    "def clip_grid_points_to_country(grid_points, country_polygon):\n",
    "    prepped = prep(country_polygon)\n",
    "    return [pt for pt in grid_points if prepped.contains(Point(pt[1], pt[0]))]\n",
    "\n",
    "def filter_conflicts(df, country_code, year):\n",
    "    return df[(df['year'] == year) & df['country_id'].astype(str).str.contains(str(country_code))]\n",
    "\n",
    "def get_conflict_coordinates(df):\n",
    "    return df[['latitude', 'longitude']].dropna().values.tolist()\n",
    "\n",
    "def process_country_code(country_code, years, countries, event_csv, df_pop, all_data):\n",
    "    summary_rows = []\n",
    "    heatmap_points = []\n",
    "\n",
    "    iso3 = next((iso for iso, code in ISO_GW.items() if str(code) == country_code), None)\n",
    "    if not iso3:\n",
    "        logger.warning(f\"ISO3 code not found for country_code: {country_code}\")\n",
    "        return None\n",
    "\n",
    "    iso2 = ISO_ISO2[iso3]\n",
    "    country_gdf = countries[countries['ISO'] == iso2]\n",
    "    if country_gdf.empty:\n",
    "        logger.warning(f\"Country geometry not found for ISO3: {iso3}/ ISO2: {iso2})\")\n",
    "        return None\n",
    "\n",
    "    polygon = country_gdf.geometry.iloc[0]\n",
    "\n",
    "    for yr in years:\n",
    "        conflict_df = filter_conflicts(event_csv, country_code, yr)\n",
    "        coords = get_conflict_coordinates(conflict_df)\n",
    "\n",
    "        if not coords:\n",
    "            pop_in_conflict = 0\n",
    "            union_grid_points = []\n",
    "        else:\n",
    "            pop_in_conflict, union_grid_points = get_population_in_conflict_area(all_data, coords)\n",
    "            union_grid_points = clip_grid_points_to_country(union_grid_points, polygon)\n",
    "            pop_in_conflict = sum(pt[2] for pt in union_grid_points)\n",
    "            # store grid with year tag\n",
    "            for pt in union_grid_points:\n",
    "                heatmap_points.append({\n",
    "                    'year': yr,\n",
    "                    'latitude': pt[0],\n",
    "                    'longitude': pt[1],\n",
    "                    'population': pt[2]\n",
    "                })\n",
    "\n",
    "        national_pop = df_pop[(df_pop['ISO_code'] == iso3) & (df_pop['Year'] == yr)]['Population']\n",
    "        if not national_pop.empty and national_pop.iloc[0] > 0:\n",
    "            pct = (pop_in_conflict / national_pop.iloc[0]) * 100\n",
    "        else:\n",
    "            pct = None\n",
    "\n",
    "        summary_rows.append({\n",
    "            'gw_code': country_code,\n",
    "            'iso3': iso3,\n",
    "            'year': yr,\n",
    "            'pop_in_conflict': pop_in_conflict,\n",
    "            'national_pop': national_pop.iloc[0] if not national_pop.empty else None,\n",
    "            'percent': pct\n",
    "        })\n",
    "\n",
    "    # Save individual files\n",
    "    pd.DataFrame(summary_rows).to_csv(processed_data_path(\"shocks\", \"proximity_conflict\", f\"conflict_summary_{iso3}.csv\"),index=False)\n",
    "    pd.DataFrame(heatmap_points).to_csv(processed_data_path(\"shocks\", \"proximity_conflict\", f\"heatmap_grid_{iso3}.csv\"),index=False)\n",
    "\n",
    "    return iso3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff82df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbuc0011\\AppData\\Local\\Temp\\ipykernel_41892\\3619748554.py:17: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  event_csv = pd.read_csv(raw_data_path(\"shocks\", \"GEDEvent_v25_1.csv\"))\n"
     ]
    }
   ],
   "source": [
    "# Load shared data (outside parallel scope)\n",
    "\n",
    "## POPULATION DNESITY\n",
    "all_data = []\n",
    "for tile in range(1, 9):\n",
    "    fp = raw_data_path(\"shocks\", \"gpw-v4\", FILE_PATTERN.format(tile=tile))\n",
    "    result = read_population_count(fp)\n",
    "    if result:\n",
    "        all_data.append(result)\n",
    "\n",
    "## SHAPEFILE\n",
    "# TODO: make secondary shapefile dataset when country not availbale in first\n",
    "countries = gpd.read_file(raw_data_path(\"shocks\", \"country_shapefiles\", \"World_Countries_Generalized.shp\")).to_crs(\"EPSG:4326\")\n",
    "\n",
    "## CONFLICT EVENTS\n",
    "UcdpPrioConflict_csv = pd.read_csv(raw_data_path(\"shocks\", \"UcdpPrioConflict_v25_1.csv\"))\n",
    "event_csv = pd.read_csv(raw_data_path(\"shocks\", \"GEDEvent_v25_1.csv\"))\n",
    "event_csv = event_csv[event_csv['conflict_new_id'].isin(UcdpPrioConflict_csv['conflict_id'].unique())]\n",
    "\n",
    "# fitler events, at least one fatality, also more than one death at event per country per year per dyad (i.e. exclude small conflicts)\n",
    "event_csv = event_csv[event_csv['best'] > 0]\n",
    "\n",
    "# total deaths per dyad-country-year\n",
    "death_sums = (\n",
    "    event_csv.groupby(['dyad_new_id', 'country_id', 'year'])['best']\n",
    "    .sum()\n",
    "    .reset_index(name='group_best_sum')\n",
    ")\n",
    "\n",
    "# Keep only groups where total deaths > 1\n",
    "valid_groups = death_sums[death_sums['group_best_sum'] > 1]\n",
    "\n",
    "# Merge back to filter the original event-level data\n",
    "event_csv = event_csv.merge(\n",
    "    valid_groups[['dyad_new_id', 'country_id', 'year']],\n",
    "    on=['dyad_new_id', 'country_id', 'year'],\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df08dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pop = pd.read_excel(\n",
    "#     raw_data_path(\"shocks\", 'WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx'),\n",
    "#     sheet_name=\"Estimates\", skiprows=16\n",
    "# )[['ISO3 Alpha-code', 'Year', 'Total Population, as of 1 January (thousands)']]\n",
    "# df_pop.columns = ['ISO_code', 'Year', 'Population']\n",
    "# df_pop.dropna(inplace=True)\n",
    "# df_pop['Year'] = df_pop['Year'].astype(int)\n",
    "# df_pop['Population'] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18a4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## POPULATION\n",
    "\n",
    "# this can go into utils and combine/replace son bias, same data source\n",
    "CONFIG = {\n",
    "    \"son_bias\": {\n",
    "        \"file\": \"WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx\",\n",
    "        \"sheet\": \"Estimates\",\n",
    "        \"indicator_col\": \"Sex Ratio at Birth (males per 100 female births)\",\n",
    "        \"output_col\": \"Son Bias\",\n",
    "    },\n",
    "    \"son_bias_medium\": {\n",
    "        \"file\": \"WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx\",\n",
    "        \"sheet\": \"Medium variant\",\n",
    "        \"indicator_col\": \"Sex Ratio at Birth (males per 100 female births)\",\n",
    "        \"output_col\": \"Son Bias\",\n",
    "    },\n",
    "    \"total_population\": {\n",
    "        \"file\": \"WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx\",\n",
    "        \"sheet\": \"Estimates\",\n",
    "        \"indicator_col\": \"Total Population, as of 1 January (thousands)\",\n",
    "        \"output_col\": \"Population\",\n",
    "    },\n",
    "    \"total_population_medium\": {\n",
    "        \"file\": \"WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx\",\n",
    "        \"sheet\": \"Medium variant\",\n",
    "        \"indicator_col\": \"Total Population, as of 1 January (thousands)\",\n",
    "        \"output_col\": \"Population\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def load_raw(name: str) -> pd.DataFrame:\n",
    "    cfg = CONFIG[name]\n",
    "    path = raw_data_path(\"indicators\", cfg[\"file\"])\n",
    "    return pd.read_excel(path, sheet_name=cfg[\"sheet\"], skiprows=16)\n",
    "\n",
    "\n",
    "def process_indicator_raw(\n",
    "    df: pd.DataFrame, config_key: str, iso_codes: list[str] | None = None\n",
    ") -> pd.DataFrame:\n",
    "    cfg = CONFIG[config_key]\n",
    "    indicator_col = cfg[\"indicator_col\"]\n",
    "    output_col = cfg[\"output_col\"]\n",
    "\n",
    "    cols = [\"ISO3 Alpha-code\", \"Year\", indicator_col]\n",
    "    df = df[cols].dropna(subset=cols)\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"ISO3 Alpha-code\": \"ISO_code\",\n",
    "            indicator_col: output_col,\n",
    "        }\n",
    "    )\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[output_col] = pd.to_numeric(df[output_col], errors=\"coerce\")\n",
    "\n",
    "    if iso_codes is not None:\n",
    "        df = df[df[\"ISO_code\"].isin(iso_codes)]\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def build_indicator_df(\n",
    "    base_key: str, projection_key: str, projection_years=[2024, 2025], iso_codes: list[str] | None = None\n",
    ") -> pd.DataFrame:\n",
    "    df_hist = process_indicator_raw(load_raw(base_key), base_key, iso_codes)\n",
    "    df_proj = (\n",
    "        process_indicator_raw(load_raw(projection_key), projection_key, iso_codes)\n",
    "        .query(\"Year in @projection_years\")\n",
    "    )\n",
    "\n",
    "    output_col = CONFIG[base_key][\"output_col\"]\n",
    "\n",
    "    combined = pd.concat(\n",
    "        [df_hist[[\"ISO_code\", \"Year\", output_col]], df_proj[[\"ISO_code\", \"Year\", output_col]]],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80d4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Total Population\n",
    "df_pop = build_indicator_df(\"total_population\", \"total_population_medium\")\n",
    "df_pop.dropna(inplace=True)\n",
    "df_pop['Year'] = df_pop['Year'].astype(int)\n",
    "df_pop['Population'] *= 1000\n",
    "\n",
    "# Save all lat/long of relevant events\n",
    "# Invert ISO_GW: {GW_code → ISO3}\n",
    "GW_ISO = {str(v): k for k, v in ISO_GW.items()}\n",
    "event_csv['ISO3'] = event_csv['country_id'].astype(str).map(GW_ISO)\n",
    "all_events = event_csv[['year', 'country_id', 'conflict_name', 'dyad_name', 'best','latitude', 'longitude']].copy()\n",
    "all_events.to_csv(processed_data_path(\"shocks\", \"proximity_conflict\", f\"event_level_coords.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37185fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved results for AUS\n"
     ]
    }
   ],
   "source": [
    "# Parallel execution\n",
    "years = list(range(1995,2025))\n",
    "\n",
    "valid_gw_codes = [\"811\", \"840\", \"850\", \"900\"]  # Cambodia, Phillipines, Indonesia, Australia\n",
    "valid_gw_codes = [\"900\"] #Afghanistan\n",
    "valid_gw_codes = GW_ISO.keys()\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "completed = []\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(process_country_code, code, years, countries, event_csv, df_pop, all_data): code for code in valid_gw_codes}\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            completed.append(result)\n",
    "            print(f\"✅ Saved results for {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
